# OpenAI Responses API: перевод и Structured Outputs (практика для Web2RU)

## 1) Базовая стратегия (из ТЗ)
- модель по умолчанию: `gpt-5.1`
- reasoning.effort по умолчанию: `medium` (если режим `none` — не отправляем поле reasoning вовсе)
- Structured Outputs: `text.format = { type: "json_schema", strict: true, schema: ... }`
- max_output_tokens: 8192 (дефолт), но контролируется флагом CLI.

## 2) Что важно помнить (инженерная реальность)
1. **Strict schema — не магия.** Всё равно валидируем:
   - parse JSON,
   - соответствие схеме,
   - наличие 1:1 переводов по всем id,
   - сохранность placeholders Token Protector.
2. **LLM может “терять текст”.** Поэтому:
   - retry,
   - auto-split батча,
   - fallback (block → textnode),
   - если и так не получается — оставляем оригинал и честно пишем в report.
3. **Стоимость и латентность** обычно растут из-за:
   - слишком больших батчей,
   - повторов (retries),
   - слишком большого max_output_tokens,
   - слишком “тяжёлого” reasoning.

## 3) Версионирование промпта и схемы
Чтобы кеш переводов был корректным:
- иметь `PROMPT_VERSION`,
- иметь `TOKEN_PROTECTOR_VERSION`,
- иметь `GLOSSARY_VERSION`,
- включать их в hash ключ кеша (как в ТЗ).

## 4) Рекомендованные техники контроля качества перевода
- словарь/глоссарий на брендовые и технические термины,
- тесты на “инварианты” (URL/flags/ids не меняются),
- эвристики на “HTML/Markdown в ответе” как hard error,
- метрики empty-parts (в режиме allow-empty-parts=on).

## 5) Границы автоматизации (где не доверяем модели)
- Любая строка, похожая на код/CLI/идентификатор — должна быть защищена Token Protector.
- Любая попытка модели добавить форматирование — ошибка.
- Любые новые id или перестановка id — ошибка.
